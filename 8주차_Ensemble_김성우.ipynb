{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMto9JQRx0h0lpOnOHOvEnU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iguv221/Tobigs_Assignment/blob/main/11_AE_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## google colab 을 사용했기 때문에 drive mount 을 함\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JpHI7bqzGr-",
        "outputId": "a3de30d8-64eb-451b-9e3a-69fea42664af"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "n33h3yWLx5t4"
      },
      "outputs": [],
      "source": [
        "## 필요 클래스 임포트\n",
        "\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.metrics import f1_score\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 구글 코렙에서는 무료로 GPU 제한적으로 사용 가능하기 때문에 device 에 미리 세팅을 합니다.\n",
        "\n",
        "GPU_NUM = 0\n",
        "device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available else 'cpu')\n",
        "torch.cuda.set_device(device)\n",
        "\n",
        "print(torch.cuda.get_device_name(0))\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXbKoNELyt77",
        "outputId": "0c3cbe0c-74c3-4ea9-e5ce-b9e3757a99b2"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla T4\n",
            "True\n",
            "1.12.1+cu113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Train data 을 받아들입니다.\n",
        "## 신용카드와 관련된 데이터이지만 일반적인 정형 데이터와 다르게 각 column 에 대한 설명이나 특징이 없습니다.\n",
        "\n",
        "Train_Data = pd.read_csv('/content/drive/MyDrive/ToBigs/첫 데이콘/Data/train.csv')\n",
        "Train_Data = Train_Data.drop(columns=['ID'])\n",
        "Train_Data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "xjVH7krMzB2_",
        "outputId": "c6c2ec47-49d1-4225-9197-3e1352035d09"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         V1        V2        V3        V4        V5        V6        V7  \\\n",
              "0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
              "1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
              "2 -0.425966  0.960523  1.141109 -0.168252  0.420987 -0.029728  0.476201   \n",
              "3 -0.644269  1.417964  1.074380 -0.492199  0.948934  0.428118  1.120631   \n",
              "4 -0.894286  0.286157 -0.113192 -0.271526  2.669599  3.721818  0.370145   \n",
              "\n",
              "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
              "0  0.247676 -1.514654  0.207643  ...  0.247998  0.771679  0.909412 -0.689281   \n",
              "1  0.377436 -1.387024 -0.054952  ... -0.108300  0.005274 -0.190321 -1.175575   \n",
              "2  0.260314 -0.568671 -0.371407  ... -0.208254 -0.559825 -0.026398 -0.371427   \n",
              "3 -3.807864  0.615375  1.249376  ...  1.943465 -1.015455  0.057504 -0.649709   \n",
              "4  0.851084 -0.392048 -0.410430  ... -0.073425 -0.268092 -0.204233  1.011592   \n",
              "\n",
              "        V25       V26       V27       V28       V29       V30  \n",
              "0 -0.327642 -0.139097 -0.055353 -0.059752  4.983721 -0.994972  \n",
              "1  0.647376 -0.221929  0.062723  0.061458  1.418291 -0.994972  \n",
              "2 -0.232794  0.105915  0.253844  0.081080 -0.256131 -0.994960  \n",
              "3 -0.415267 -0.051634 -1.206921 -1.085339  0.262698 -0.994901  \n",
              "4  0.373205 -0.384157  0.011747  0.142404  0.994900 -0.994901  \n",
              "\n",
              "[5 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-029abb16-641d-4297-bd68-b42da9ca6318\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>V29</th>\n",
              "      <th>V30</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>0.207643</td>\n",
              "      <td>...</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>4.983721</td>\n",
              "      <td>-0.994972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>-0.054952</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>1.418291</td>\n",
              "      <td>-0.994972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.425966</td>\n",
              "      <td>0.960523</td>\n",
              "      <td>1.141109</td>\n",
              "      <td>-0.168252</td>\n",
              "      <td>0.420987</td>\n",
              "      <td>-0.029728</td>\n",
              "      <td>0.476201</td>\n",
              "      <td>0.260314</td>\n",
              "      <td>-0.568671</td>\n",
              "      <td>-0.371407</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.208254</td>\n",
              "      <td>-0.559825</td>\n",
              "      <td>-0.026398</td>\n",
              "      <td>-0.371427</td>\n",
              "      <td>-0.232794</td>\n",
              "      <td>0.105915</td>\n",
              "      <td>0.253844</td>\n",
              "      <td>0.081080</td>\n",
              "      <td>-0.256131</td>\n",
              "      <td>-0.994960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.644269</td>\n",
              "      <td>1.417964</td>\n",
              "      <td>1.074380</td>\n",
              "      <td>-0.492199</td>\n",
              "      <td>0.948934</td>\n",
              "      <td>0.428118</td>\n",
              "      <td>1.120631</td>\n",
              "      <td>-3.807864</td>\n",
              "      <td>0.615375</td>\n",
              "      <td>1.249376</td>\n",
              "      <td>...</td>\n",
              "      <td>1.943465</td>\n",
              "      <td>-1.015455</td>\n",
              "      <td>0.057504</td>\n",
              "      <td>-0.649709</td>\n",
              "      <td>-0.415267</td>\n",
              "      <td>-0.051634</td>\n",
              "      <td>-1.206921</td>\n",
              "      <td>-1.085339</td>\n",
              "      <td>0.262698</td>\n",
              "      <td>-0.994901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.894286</td>\n",
              "      <td>0.286157</td>\n",
              "      <td>-0.113192</td>\n",
              "      <td>-0.271526</td>\n",
              "      <td>2.669599</td>\n",
              "      <td>3.721818</td>\n",
              "      <td>0.370145</td>\n",
              "      <td>0.851084</td>\n",
              "      <td>-0.392048</td>\n",
              "      <td>-0.410430</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.073425</td>\n",
              "      <td>-0.268092</td>\n",
              "      <td>-0.204233</td>\n",
              "      <td>1.011592</td>\n",
              "      <td>0.373205</td>\n",
              "      <td>-0.384157</td>\n",
              "      <td>0.011747</td>\n",
              "      <td>0.142404</td>\n",
              "      <td>0.994900</td>\n",
              "      <td>-0.994901</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-029abb16-641d-4297-bd68-b42da9ca6318')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-029abb16-641d-4297-bd68-b42da9ca6318 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-029abb16-641d-4297-bd68-b42da9ca6318');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Valid data 을 받아들입니다.\n",
        "## Valid data 은 train data 에 과적합되는 것을 방지하기 위한 데이터셋으로 \n",
        "## 직접적인 학습에 사용하지 않고 새로운 데이터에서도 좋은 성능을 내는지 확인하기 위해 쓰입니다.\n",
        "\n",
        "Valid_Data = pd.read_csv('/content/drive/MyDrive/ToBigs/첫 데이콘/Data/val.csv')\n",
        "Valid_Data = Valid_Data.drop(columns=['ID'])\n",
        "Valid_Data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "AzKvUGFmy19q",
        "outputId": "b33a087b-bdf7-4e1b-a1a7-c02c349d05a6"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         V1        V2        V3        V4        V5        V6        V7  \\\n",
              "0 -0.338262  1.119593  1.044367 -0.222187  0.499361 -0.246761  0.651583   \n",
              "1  0.962496  0.328461 -0.171479  2.109204  1.129566  1.696038  0.107712   \n",
              "2  1.145524  0.575068  0.194008  2.598192 -0.092210 -1.044430  0.531588   \n",
              "3  0.927060 -0.323684  0.387585  0.544474  0.246787  1.650358 -0.427576   \n",
              "4 -3.005237  2.600138  1.483691 -2.418473  0.306326 -0.824575  2.065426   \n",
              "\n",
              "         V8        V9       V10  ...       V22       V23       V24       V25  \\\n",
              "0  0.069539 -0.736727 -0.366846  ... -0.633753 -0.120794 -0.385050 -0.069733   \n",
              "1  0.521502 -1.191311  0.724396  ...  0.402492 -0.048508 -1.371866  0.390814   \n",
              "2 -0.241888 -0.896287  0.757952  ... -0.119703 -0.076510  0.691320  0.633984   \n",
              "3  0.615371  0.226278 -0.225495  ...  0.079359  0.096632 -0.992569  0.085096   \n",
              "4 -1.829347  4.009259  6.051521  ... -0.181268 -0.163747  0.515821  0.136318   \n",
              "\n",
              "        V26       V27       V28       V29       V30  Class  \n",
              "0  0.094199  0.246219  0.083076 -0.255991 -0.994878      0  \n",
              "1  0.199964  0.016371 -0.014605  0.168937 -0.994784      0  \n",
              "2  0.048741 -0.053192  0.016251  0.169496 -0.994502      0  \n",
              "3  0.377447  0.036096 -0.005960  0.331307 -0.994467      0  \n",
              "4  0.460054 -0.251259 -1.105751 -0.287012 -0.994373      0  \n",
              "\n",
              "[5 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b27154c5-9b1a-42a2-8d4c-91eb0507cfaa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>...</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>V29</th>\n",
              "      <th>V30</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.338262</td>\n",
              "      <td>1.119593</td>\n",
              "      <td>1.044367</td>\n",
              "      <td>-0.222187</td>\n",
              "      <td>0.499361</td>\n",
              "      <td>-0.246761</td>\n",
              "      <td>0.651583</td>\n",
              "      <td>0.069539</td>\n",
              "      <td>-0.736727</td>\n",
              "      <td>-0.366846</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.633753</td>\n",
              "      <td>-0.120794</td>\n",
              "      <td>-0.385050</td>\n",
              "      <td>-0.069733</td>\n",
              "      <td>0.094199</td>\n",
              "      <td>0.246219</td>\n",
              "      <td>0.083076</td>\n",
              "      <td>-0.255991</td>\n",
              "      <td>-0.994878</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.962496</td>\n",
              "      <td>0.328461</td>\n",
              "      <td>-0.171479</td>\n",
              "      <td>2.109204</td>\n",
              "      <td>1.129566</td>\n",
              "      <td>1.696038</td>\n",
              "      <td>0.107712</td>\n",
              "      <td>0.521502</td>\n",
              "      <td>-1.191311</td>\n",
              "      <td>0.724396</td>\n",
              "      <td>...</td>\n",
              "      <td>0.402492</td>\n",
              "      <td>-0.048508</td>\n",
              "      <td>-1.371866</td>\n",
              "      <td>0.390814</td>\n",
              "      <td>0.199964</td>\n",
              "      <td>0.016371</td>\n",
              "      <td>-0.014605</td>\n",
              "      <td>0.168937</td>\n",
              "      <td>-0.994784</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.145524</td>\n",
              "      <td>0.575068</td>\n",
              "      <td>0.194008</td>\n",
              "      <td>2.598192</td>\n",
              "      <td>-0.092210</td>\n",
              "      <td>-1.044430</td>\n",
              "      <td>0.531588</td>\n",
              "      <td>-0.241888</td>\n",
              "      <td>-0.896287</td>\n",
              "      <td>0.757952</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.119703</td>\n",
              "      <td>-0.076510</td>\n",
              "      <td>0.691320</td>\n",
              "      <td>0.633984</td>\n",
              "      <td>0.048741</td>\n",
              "      <td>-0.053192</td>\n",
              "      <td>0.016251</td>\n",
              "      <td>0.169496</td>\n",
              "      <td>-0.994502</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.927060</td>\n",
              "      <td>-0.323684</td>\n",
              "      <td>0.387585</td>\n",
              "      <td>0.544474</td>\n",
              "      <td>0.246787</td>\n",
              "      <td>1.650358</td>\n",
              "      <td>-0.427576</td>\n",
              "      <td>0.615371</td>\n",
              "      <td>0.226278</td>\n",
              "      <td>-0.225495</td>\n",
              "      <td>...</td>\n",
              "      <td>0.079359</td>\n",
              "      <td>0.096632</td>\n",
              "      <td>-0.992569</td>\n",
              "      <td>0.085096</td>\n",
              "      <td>0.377447</td>\n",
              "      <td>0.036096</td>\n",
              "      <td>-0.005960</td>\n",
              "      <td>0.331307</td>\n",
              "      <td>-0.994467</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-3.005237</td>\n",
              "      <td>2.600138</td>\n",
              "      <td>1.483691</td>\n",
              "      <td>-2.418473</td>\n",
              "      <td>0.306326</td>\n",
              "      <td>-0.824575</td>\n",
              "      <td>2.065426</td>\n",
              "      <td>-1.829347</td>\n",
              "      <td>4.009259</td>\n",
              "      <td>6.051521</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.181268</td>\n",
              "      <td>-0.163747</td>\n",
              "      <td>0.515821</td>\n",
              "      <td>0.136318</td>\n",
              "      <td>0.460054</td>\n",
              "      <td>-0.251259</td>\n",
              "      <td>-1.105751</td>\n",
              "      <td>-0.287012</td>\n",
              "      <td>-0.994373</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b27154c5-9b1a-42a2-8d4c-91eb0507cfaa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b27154c5-9b1a-42a2-8d4c-91eb0507cfaa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b27154c5-9b1a-42a2-8d4c-91eb0507cfaa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Class column 이 Y value 인데 이를 제외한 나머지 column 을 scaling 하려고 합니다.\n",
        "## 그러기 위해서 Columns 이라는 list 에 나머지 column 들의 이름을 저장해둡니다.\n",
        "\n",
        "Columns = []\n",
        "for i in range(1,31):\n",
        "    Columns.append('V'+str(i))"
      ],
      "metadata": {
        "id": "d5HE4LpzVKFk"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Columns 을 이용해 scaling 을 진행합니다.\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "SS = StandardScaler()\n",
        "SS.fit(Train_Data)\n",
        "\n",
        "Train_Data[Columns] = SS.transform(Train_Data[Columns])\n",
        "Train_Data[Columns] = pd.DataFrame(Train_Data[Columns])\n",
        "Valid_Data[Columns] = SS.transform(Valid_Data[Columns])\n",
        "Valid_Data[Columns] = pd.DataFrame(Valid_Data[Columns])\n",
        "\n",
        "Valid_Data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "PWtz1m22T76u",
        "outputId": "5396af35-99e4-4116-e348-9d88ecb4fa6d"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         V1        V2        V3        V4        V5        V6        V7  \\\n",
              "0 -0.173475  0.677327  0.691190 -0.154335  0.364809 -0.189318  0.536344   \n",
              "1  0.493220  0.198159 -0.121047  1.496059  0.825644  1.270800  0.084662   \n",
              "2  0.587031  0.347522  0.123114  1.842214 -0.067776 -0.788809  0.436688   \n",
              "3  0.475058 -0.196827  0.252432  0.388385  0.180115  1.236469 -0.359890   \n",
              "4 -1.540417  1.574053  0.984678 -1.709088  0.223653 -0.623576  1.710528   \n",
              "\n",
              "         V8        V9       V10  ...       V22       V23       V24       V25  \\\n",
              "0  0.060725 -0.670635 -0.347282  ... -0.875560 -0.187839 -0.634092 -0.137315   \n",
              "1  0.441968 -1.085624  0.671301  ...  0.556061 -0.074193 -2.262901  0.748237   \n",
              "2 -0.201972 -0.816297  0.702623  ... -0.165376 -0.118216  1.142531  1.215812   \n",
              "3  0.521149  0.208493 -0.215344  ...  0.109638  0.153994 -1.636844  0.160394   \n",
              "4 -1.541035  3.661975  5.643730  ... -0.250432 -0.255368  0.852857  0.258886   \n",
              "\n",
              "        V26       V27       V28       V29       V30  Class  \n",
              "0  0.196459  0.616898  0.234701 -0.346696 -1.990670      0  \n",
              "1  0.416355  0.041562 -0.039585 -0.222190 -1.990502      0  \n",
              "2  0.101948 -0.132560  0.047060 -0.222026 -1.989997      0  \n",
              "3  0.785362  0.090938 -0.015310 -0.174615 -1.989933      0  \n",
              "4  0.957110 -0.628342 -3.103499 -0.355785 -1.989765      0  \n",
              "\n",
              "[5 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6df54b87-3885-4396-9052-5652d7be6a9e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>...</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>V29</th>\n",
              "      <th>V30</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.173475</td>\n",
              "      <td>0.677327</td>\n",
              "      <td>0.691190</td>\n",
              "      <td>-0.154335</td>\n",
              "      <td>0.364809</td>\n",
              "      <td>-0.189318</td>\n",
              "      <td>0.536344</td>\n",
              "      <td>0.060725</td>\n",
              "      <td>-0.670635</td>\n",
              "      <td>-0.347282</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.875560</td>\n",
              "      <td>-0.187839</td>\n",
              "      <td>-0.634092</td>\n",
              "      <td>-0.137315</td>\n",
              "      <td>0.196459</td>\n",
              "      <td>0.616898</td>\n",
              "      <td>0.234701</td>\n",
              "      <td>-0.346696</td>\n",
              "      <td>-1.990670</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.493220</td>\n",
              "      <td>0.198159</td>\n",
              "      <td>-0.121047</td>\n",
              "      <td>1.496059</td>\n",
              "      <td>0.825644</td>\n",
              "      <td>1.270800</td>\n",
              "      <td>0.084662</td>\n",
              "      <td>0.441968</td>\n",
              "      <td>-1.085624</td>\n",
              "      <td>0.671301</td>\n",
              "      <td>...</td>\n",
              "      <td>0.556061</td>\n",
              "      <td>-0.074193</td>\n",
              "      <td>-2.262901</td>\n",
              "      <td>0.748237</td>\n",
              "      <td>0.416355</td>\n",
              "      <td>0.041562</td>\n",
              "      <td>-0.039585</td>\n",
              "      <td>-0.222190</td>\n",
              "      <td>-1.990502</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.587031</td>\n",
              "      <td>0.347522</td>\n",
              "      <td>0.123114</td>\n",
              "      <td>1.842214</td>\n",
              "      <td>-0.067776</td>\n",
              "      <td>-0.788809</td>\n",
              "      <td>0.436688</td>\n",
              "      <td>-0.201972</td>\n",
              "      <td>-0.816297</td>\n",
              "      <td>0.702623</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.165376</td>\n",
              "      <td>-0.118216</td>\n",
              "      <td>1.142531</td>\n",
              "      <td>1.215812</td>\n",
              "      <td>0.101948</td>\n",
              "      <td>-0.132560</td>\n",
              "      <td>0.047060</td>\n",
              "      <td>-0.222026</td>\n",
              "      <td>-1.989997</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.475058</td>\n",
              "      <td>-0.196827</td>\n",
              "      <td>0.252432</td>\n",
              "      <td>0.388385</td>\n",
              "      <td>0.180115</td>\n",
              "      <td>1.236469</td>\n",
              "      <td>-0.359890</td>\n",
              "      <td>0.521149</td>\n",
              "      <td>0.208493</td>\n",
              "      <td>-0.215344</td>\n",
              "      <td>...</td>\n",
              "      <td>0.109638</td>\n",
              "      <td>0.153994</td>\n",
              "      <td>-1.636844</td>\n",
              "      <td>0.160394</td>\n",
              "      <td>0.785362</td>\n",
              "      <td>0.090938</td>\n",
              "      <td>-0.015310</td>\n",
              "      <td>-0.174615</td>\n",
              "      <td>-1.989933</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.540417</td>\n",
              "      <td>1.574053</td>\n",
              "      <td>0.984678</td>\n",
              "      <td>-1.709088</td>\n",
              "      <td>0.223653</td>\n",
              "      <td>-0.623576</td>\n",
              "      <td>1.710528</td>\n",
              "      <td>-1.541035</td>\n",
              "      <td>3.661975</td>\n",
              "      <td>5.643730</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.250432</td>\n",
              "      <td>-0.255368</td>\n",
              "      <td>0.852857</td>\n",
              "      <td>0.258886</td>\n",
              "      <td>0.957110</td>\n",
              "      <td>-0.628342</td>\n",
              "      <td>-3.103499</td>\n",
              "      <td>-0.355785</td>\n",
              "      <td>-1.989765</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6df54b87-3885-4396-9052-5652d7be6a9e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6df54b87-3885-4396-9052-5652d7be6a9e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6df54b87-3885-4396-9052-5652d7be6a9e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Custom_Dataset(Dataset):\n",
        "    def __init__(self, data, eval_mode):  \n",
        "        # 원래 이런 eval_mode 잘 없는데 train 은 y 가 없고 valid 은 y 가 있는 점 때문에 필요한 장치입니다.\n",
        "        # 원래는 eval_mode 없이 그냥 train valid 모두 다 y 가 있었으면 아래에 전부 다 iter enumerate 쓰면 됩니다.\n",
        "        self.Data = data\n",
        "        self.Eval_Mode = eval_mode\n",
        "        if self.Eval_Mode:\n",
        "            self.labels = self.Data['Class'].values\n",
        "            self.Data = self.Data.drop(columns=['Class']).values\n",
        "        else:\n",
        "            self.Data = self.Data.values\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        if self.Eval_Mode:\n",
        "            self.x = torch.Tensor(self.Data[index])\n",
        "            self.y = self.labels[index]\n",
        "            return self.x,self.y\n",
        "        else:\n",
        "            return torch.Tensor(self.Data[index])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.Data)"
      ],
      "metadata": {
        "id": "CYmVauoCy2AR"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ayopOYPGy2Cm"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 모델 설계하는 부분입니다.\n",
        "\n",
        "## 처음 시작할때는 weighted XGBoost 알고리즘을 사용하다가 성능에 한계가 보여서 간단한 딥러닝 모델을 구현하려고 했습니다.\n",
        "## 이때 다른 사이트 참고하면서 임의로 만들었지만 성능이 XGBoost 보다는 좋았지만 기대 이하의 성능을 보였습니다.\n",
        "## 계속 고민하다 코드공유에 아래 코드의 출처가 올라왔고 매우 좋은 성능을 보였다 ㅎ;;\n",
        "## 그 코드 기반으로 조금 더 수정하고 보완을 해 최종 결과를 냈습니다.\n",
        "\n",
        "class AE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AE,self).__init__()\n",
        "        self.Encoder = nn.Sequential(\n",
        "            nn.Linear(30,64),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Linear(64,128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            # nn.Linear(128,256),\n",
        "            # nn.BatchNorm1d(256),\n",
        "            # nn.ReLU(),\n",
        "\n",
        "            # nn.Linear(128,64),\n",
        "            # nn.BatchNorm1d(64),\n",
        "            # nn.ReLU(),\n",
        "\n",
        "            # nn.Linear(64,16),\n",
        "            # nn.BatchNorm1d(16),\n",
        "            # nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.Decoder = nn.Sequential(\n",
        "            # nn.Linear(256,128),\n",
        "            # nn.BatchNorm1d(128),\n",
        "            # nn.ReLU(),\n",
        "\n",
        "            # nn.Linear(16,64),\n",
        "            # nn.BatchNorm1d(64),\n",
        "            # nn.ReLU(),\n",
        "\n",
        "            # nn.Linear(64,128),\n",
        "            # nn.BatchNorm1d(128),\n",
        "            # nn.ReLU(),\n",
        "\n",
        "            nn.Linear(128,64),\n",
        "            # nn.BatchNorm1d(64),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Linear(64,30),\n",
        "        )\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.Encoder(x)\n",
        "        x = self.Decoder(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "sJYbBlSezu6J"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 파라미터 설정.\n",
        "\n",
        "epochs = 150\n",
        "batch_size = 1024\n",
        "lr = 0.0003\n",
        "Dist_eps = 0.0000008\n",
        "alpha_range = 0.95\n",
        "Valid_Times = 20\n"
      ],
      "metadata": {
        "id": "i3qL0KAezu8n"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 데이터셋을 mini-batch stochastic learning 에 사용할 수 있게 1024 크기의 batch 으로 만듭니다.\n",
        "\n",
        "Custom_Train_Data = Custom_Dataset(Train_Data,eval_mode = False)\n",
        "train_loader = DataLoader(Custom_Train_Data, batch_size = batch_size, shuffle=True, num_workers=2)\n",
        "Custom_Valid_Data = Custom_Dataset(Valid_Data,eval_mode = True)\n",
        "valid_loader = DataLoader(Custom_Valid_Data, batch_size = batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "train_loader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1Pwy_xxXYo7",
        "outputId": "b253ee09-fea4-4e4c-d9a8-21258a502dbe"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7fc82d247d50>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 모델을 선언하고 학습을 시킵니다.\n",
        "\n",
        "AEmodel = nn.DataParallel(AE())\n",
        "AEmodel.eval()\n",
        "optimizer = torch.optim.Adam(params = AEmodel.parameters(), lr = lr)\n",
        "cos = nn.CosineSimilarity(dim=1, eps=Dist_eps).to(device)\n",
        "criterion = nn.L1Loss().to(device)\n",
        "\n",
        "score=0\n",
        "for epoch in range(epochs):\n",
        "    AEmodel.train()\n",
        "    train_loss=[]\n",
        "    for data_x in iter(train_loader):\n",
        "\n",
        "        data_x = data_x.float().to(device)\n",
        "        pred_x = AEmodel(data_x)\n",
        "        loss = criterion(data_x,pred_x)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss.append(loss.item())\n",
        "\n",
        "    if (epoch+1)%(int(epochs/Valid_Times))==0:\n",
        "        AEmodel.eval()\n",
        "        pred = []\n",
        "        true = []\n",
        "        with torch.no_grad():\n",
        "            for data_x, label in iter(valid_loader):\n",
        "                data_x = data_x.float().to(device)\n",
        "\n",
        "                pred_x = AEmodel(data_x)\n",
        "                diff = cos(data_x, pred_x).cpu().tolist()\n",
        "                batch_pred = np.where(np.array(diff)<alpha_range, 1,0).tolist()\n",
        "                pred += batch_pred\n",
        "                true += label.tolist()\n",
        "\n",
        "        f1score = f1_score(true, pred, average='macro')\n",
        "        print(\"Epoch : [{} / {}], Train Loss : {:.4f}, Valid F1Score : {:.4f}\".format(epoch+1,epochs,np.mean(train_loss),f1score))\n"
      ],
      "metadata": {
        "id": "HZcb_wv0-lRF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f80cd4b-a193-401d-de3e-7cf2ec9b3d34"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : [7 / 150], Train Loss : 0.1410, Valid F1Score : 0.4871\n",
            "Epoch : [14 / 150], Train Loss : 0.1090, Valid F1Score : 0.5067\n",
            "Epoch : [21 / 150], Train Loss : 0.0915, Valid F1Score : 0.5387\n",
            "Epoch : [28 / 150], Train Loss : 0.0838, Valid F1Score : 0.5407\n",
            "Epoch : [35 / 150], Train Loss : 0.0766, Valid F1Score : 0.6993\n",
            "Epoch : [42 / 150], Train Loss : 0.0708, Valid F1Score : 0.8376\n",
            "Epoch : [49 / 150], Train Loss : 0.0669, Valid F1Score : 0.8470\n",
            "Epoch : [56 / 150], Train Loss : 0.0651, Valid F1Score : 0.8622\n",
            "Epoch : [63 / 150], Train Loss : 0.0620, Valid F1Score : 0.8786\n",
            "Epoch : [70 / 150], Train Loss : 0.0610, Valid F1Score : 0.8845\n",
            "Epoch : [77 / 150], Train Loss : 0.0581, Valid F1Score : 0.8845\n",
            "Epoch : [84 / 150], Train Loss : 0.0560, Valid F1Score : 0.8905\n",
            "Epoch : [91 / 150], Train Loss : 0.0571, Valid F1Score : 0.8845\n",
            "Epoch : [98 / 150], Train Loss : 0.0557, Valid F1Score : 0.8967\n",
            "Epoch : [105 / 150], Train Loss : 0.0543, Valid F1Score : 0.9031\n",
            "Epoch : [112 / 150], Train Loss : 0.0525, Valid F1Score : 0.9097\n",
            "Epoch : [119 / 150], Train Loss : 0.0532, Valid F1Score : 0.9031\n",
            "Epoch : [126 / 150], Train Loss : 0.0535, Valid F1Score : 0.9031\n",
            "Epoch : [133 / 150], Train Loss : 0.0530, Valid F1Score : 0.9166\n",
            "Epoch : [140 / 150], Train Loss : 0.0513, Valid F1Score : 0.9097\n",
            "Epoch : [147 / 150], Train Loss : 0.0503, Valid F1Score : 0.9031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 예측 함수를 만듭니다.\n",
        "\n",
        "def Predict(model, x_data_loaded):\n",
        "    model.eval()\n",
        "    pred=[]\n",
        "    with torch.no_grad():\n",
        "        for data_x in iter(x_data_loaded):\n",
        "            data_x = data_x.float().to(device)\n",
        "            pred_x = AEmodel(data_x)\n",
        "            diff = cos(data_x,pred_x).cpu().tolist()\n",
        "            batch_pred = np.where(np.array(diff)<alpha_range,1,0).tolist()\n",
        "            pred+=batch_pred\n",
        "    return pred"
      ],
      "metadata": {
        "id": "PpG9-geA-lww"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Imbalanced Dataset 인 만큼 Accuracy 보다 f1score 이 훨씬 중요한 척도입니다.\n",
        "## f1score 을 구하는 함수를 만듭니다.\n",
        "\n",
        "def f1score(Real,Pred) :\n",
        "    Pred = np.array(Pred)\n",
        "    y = np.array(Real)\n",
        "    TP = np.sum((Pred == 1) & (y == 1))\n",
        "    FP = np.sum((Pred == 1) & (y != 1))\n",
        "    FN = np.sum((Pred != 1) & (y == 1))\n",
        "    TN = np.sum((Pred != 1) & (y != 1))\n",
        "    Precision = (TP)/(TP+FP)\n",
        "    Recall = (TP)/(TP+FN)\n",
        "    score = 2*(Precision*Recall)/(Precision+Recall)\n",
        "    return score"
      ],
      "metadata": {
        "id": "1I7jP33wzvCO"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Valid data 을 통해 새로운 데이터에서도 유사한 성능을 보이는지 확인합니다.\n",
        "\n",
        "new_Valid_Data = pd.read_csv('/content/drive/MyDrive/ToBigs/첫 데이콘/Data/val.csv')\n",
        "\n",
        "valid_real = new_Valid_Data['Class']\n",
        "new_Valid_Data = new_Valid_Data.drop(columns=['ID','Class'])\n",
        "\n",
        "new_Valid_Data[Columns] = SS.transform(new_Valid_Data[Columns])\n",
        "new_Valid_Data[Columns] = pd.DataFrame(new_Valid_Data[Columns])\n",
        "Custom_new_Valid_Data = Custom_Dataset(new_Valid_Data,eval_mode = False) \n",
        "\n",
        "new_valid_loader = DataLoader(Custom_new_Valid_Data,batch_size = batch_size, shuffle=False,num_workers=2)\n",
        "valid_pred = Predict(AEmodel,new_valid_loader)\n",
        "valid_f1score = f1score(valid_real,valid_pred)\n",
        "print(f1_score(valid_real,valid_pred))"
      ],
      "metadata": {
        "id": "PVMxVZW2IRcM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1043ced0-3d2f-49e5-a5de-ee54d630bfe4"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8064516129032259\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(valid_f1score)"
      ],
      "metadata": {
        "id": "pMSnYklBPHKG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4864f04-2711-40fd-deb7-cf270fe140b6"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8064516129032259\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Valid Data F1 Score : \", valid_f1score)\n",
        "#   0.83333"
      ],
      "metadata": {
        "id": "-I0MDIgoJMKd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a597ee3d-7013-424b-fabd-a26452136226"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Data F1 Score :  0.8064516129032259\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('/content/drive/MyDrive/ToBigs/첫 데이콘/Data/test.csv')\n",
        "test_df = test_df.drop(columns=['ID'])\n",
        "test_df[Columns] = SS.transform(test_df[Columns])\n",
        "test_df[Columns] = pd.DataFrame(test_df[Columns])\n",
        "custom_test_df = Custom_Dataset(test_df,eval_mode = False)\n",
        "test_loader = DataLoader(custom_test_df,batch_size = batch_size,shuffle=False,num_workers=2)\n",
        "test_pred = Predict(AEmodel,test_loader)"
      ],
      "metadata": {
        "id": "zO5Xzh_PFUXm"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred"
      ],
      "metadata": {
        "id": "z2MiVswLFUZw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f9bf9ca-4929-4281-e62b-2a8f2db97d84"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# submit = pd.read_csv('/content/drive/MyDrive/ToBigs/첫 데이콘/Data/sample_submission.csv')\n",
        "# print(submit.columns)\n",
        "# submit.head()"
      ],
      "metadata": {
        "id": "8GREUfOOJm3E"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# submit['Class']=test_pred\n",
        "# submit.to_csv('submit.csv')"
      ],
      "metadata": {
        "id": "va3hH3wJJnIU"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# submit.head()"
      ],
      "metadata": {
        "id": "K781bwkIJnKw"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H0OctPZUJnN0"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ucspguaaJnP-"
      },
      "execution_count": 65,
      "outputs": []
    }
  ]
}
